---
title: "Final Report"
subtitle: "Data Science 3 with R (STAT 301-3)"
author: "ateam: Allie Tong, Alani Cox-Caceres"


format:
  html:
    toc: true
    embed-resources: true
    code-fold: show
    link-external-newwindow: true
    echo: false
    
execute:
  warning: false

from: markdown+emoji 
---

## Github Repository
[https://github.com/STAT301-3-2023SP/final-project-ateam](https://github.com/STAT301-3-2023SP/final-project-ateam)

## Data Overview
Our [dataset](https://www.kaggle.com/datasets/lepchenkov/usedcarscatalog) consists of variables that describe cars in the used car market in Belarus on December 2, 2019. There are 38531 observations. Our target variable will be `is_exchangeable`, which is a factor variable that indicates `TRUE` if the used car can be exchanged with another car and `FALSE` if the used car cannot be exchanged with another car. There are 19 predictors, of which 1 is an integer, 5 are characters, 7 are numeric, and 6 are factors.

## Goal
In this exploration, we'd like to examine ways to predict if the used cars will be exchangeable based on the variables that affect that outcome the most. This is a categorical prediction problem. We want to explore what factors make a car exchangeable and will test the predictor importance of various predictors to do so.

## Data Splitting and Resampling Plan
As we mentioned in our initial exploration, our data was relatively unbalanced. To remedy this, we stratified our target variable, `is_exchangeable`, and used a 70/30 split for our training and testing data. For resampling, we used a cross-validation method. We will have 10 folds with 5 repeats.

## Feature Engineering
- We first ensured that there weren't any significant missing issues that could not be imputed and found no significant missingness.

- We looked at the relationships between each of the predictors and the outcome variable through boxplots and bar graphs. From looking at the relationships, we narrowed one of our recipes to 11 predictors. We plan to test if this improves model performance.

- Next, we looked at the distribution of the numeric predictors. We found that 5 of the numeric predictors needed either a log or square root transformation to fix their skewed distribution and created a recipe with these transformations.

  - The variable `up_counter` was heavily right skewed, and none of the transformations were fixing it. So, we decided to remove `up_counter` from this recipe.

- All of the feature engineering was done on a portion of the training set.

## Recipe Building
### Kitchen Sink

### Rec_Rel


## Models Chosen + Parameters


## Assessment Measures
The assessment measures we chose to test model performance are accuracy, and f_meas. 

* accuracy: accuracy measures the proportion of correctly classified predictions over the total number of predictions 

* f_meas: the f-measure is used to measure the accuracy of a model by using precision and recall to determine how balanced the model's performance is. It calculates the harmonic mean between precision and recall to produce a single metric. 


## Model Performance


## Issues


## Final Model Analysis


